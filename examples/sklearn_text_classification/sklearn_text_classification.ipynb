{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/fluidml/fluidml/main/logo/fluid_ml_logo.png\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fluidml/fluidml/blob/main/examples/sklearn_text_classification/sklearn_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Text Classification using FluidML and Sklearn**\n",
    "In this notebook, we'll go over some basics of FluidML and implement a complete ML pipeline that performs text classification.\n",
    "Like any other ML pipeline, this usually consists of several tasks:\n",
    "- **Dataset fetching** - Downloads and parses the dataset for text classification\n",
    "- **Dataset pre-processing** - Pre-processes the raw dataset\n",
    "- **Featurization** - Converts the raw sentences to numerical vectors\n",
    "- **Training a classifier** - Trains a logistic regression model\n",
    "- **Evaluation of classifier** - Evaluates the trained model on train/test splits\n",
    "\n",
    "With FluidML, all of these steps are naturally implemented as individual tasks which register their dependencies and are chained together to a task graph. This graph is then executed in parallel by FluidML and all results are returned at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setup**\n",
    "\n",
    "To run this example, make sure to install FluidML with the additional example requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fluidml[examples,rich-logging]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 1**: Due to the limitation of multiprocessing and jupyter, we have to import our defined tasks and some helper classes from a separate script. Hence, our task definitions are located in `sklearn_text_classification.py`, which not only implements the tasks but also the entire functionality of this example. So the interested reader can also go ahead and execute the just mentioned script. In order to still make this notebook self-explanatory, we provide Markdown code snippets of the individual task implementations at the place where we would have defined the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluidml.common import Task, Resource\n",
    "from fluidml.swarm import Swarm\n",
    "from fluidml.flow import Flow, GridTaskSpec, TaskSpec\n",
    "\n",
    "from sklearn_text_classification import DatasetFetchTask, PreProcessTask, TFIDFFeaturizeTask, GloveFeaturizeTask, TrainTask, EvaluateTask, ModelSelectionTask\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note 2**: If you want to use FluidML's logging capability, please configure a logger using Python's `logging` API. For convenience, we provide a simple utility function which configures a visually appealing logger (using a specific handler from the `rich` library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluidml.common.logging import configure_logging\n",
    "configure_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task Definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Dataset Fetching**\n",
    "\n",
    "Let's use HuggingFace's [datasets](https://huggingface.co/datasets) repository to quick get access to a text classification dataset. Specifically, we will use [TREC](https://huggingface.co/datasets/trec) which is a question classification dataset containing ~ 5k labeled questions in training set and ~500 questions in test set. The dataset contains two types of labels: fine and coarse. For simplicity, let's go ahead with coarse, with unique 6 labels.\n",
    "\n",
    "We can implement this dataset collection as a separate task on its own by inheriting from FluidML's Task class. It just has to implement a run() method and publish its results. \n",
    "For simplicity, we can implement this task to publish a nested dictionary. On the outer level, we have different splits and in each split, we will have list of sentences and labels.\n",
    "\n",
    "**Note:** This task publishes a 'raw dataset' as specified in `self.save(dataset_splits, \"raw_dataset\")` and `self.publishes = [\"raw_dataset\"]`. Only the items specified in self.publishes are passed to the downstream tasks.\n",
    "\n",
    "Here is the complete implementation of DatasetFetchTask:\n",
    "\n",
    "\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "class DatasetFetchTask(Task):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.publishes = [\"raw_dataset\"]\n",
    "\n",
    "    def _get_split(self, dataset, split):\n",
    "        if split == \"test\":\n",
    "            return dataset[split]\n",
    "        elif split in [\"train\", \"val\"]:\n",
    "            splitted = list(dataset[\"train\"])\n",
    "            split_index = int(0.7 * len(splitted))\n",
    "            return splitted[:split_index] if split == \"train\" else splitted[split_index:]\n",
    "\n",
    "    def _get_sentences_and_labels(self, dataset) -> Tuple[List[str], List[str]]:\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        for item in dataset:\n",
    "            sentences.append(item[\"text\"])\n",
    "            labels.append(item[\"label-coarse\"])\n",
    "        return sentences, labels\n",
    "\n",
    "    def run(self):\n",
    "        dataset = load_dataset(\"trec\")\n",
    "        splits = [\"train\", \"val\", \"test\"]\n",
    "        dataset_splits = {}\n",
    "        for split in splits:\n",
    "            dataset_split = self._get_split(dataset, split)\n",
    "            sentences, labels = self._get_sentences_and_labels(dataset_split)\n",
    "            split_results = {\n",
    "                \"sentences\": sentences,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "            dataset_splits[split] = split_results\n",
    "        self.save(dataset_splits, \"raw_dataset\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Dataset Pre-processing:**\n",
    "Now that we have our raw datasets prepared, next, we can apply some pre-processing to clean them up a bit, such as *removing punctuations*, *removing digits* and *making lower case* etc. \n",
    "We will implement this logic into a PreProcessTask. Additionally, this task takes a list of pre-processing steps as parameters.\n",
    "\n",
    "**Note**, this task assumes that the raw dataset is available to it as arguments of run() method. This will be automatically passed by FluidML. \n",
    "Later, when we create the PreProcess Task, we just have to connect the DatasetFetchTask as a predecessor. More on this later, when we model the flow/pipeline.\n",
    "\n",
    "Therefore, PreProcessTask just has to implement its own logic and publish pre-processed sentences as results. In this way, we can implement the tasks individually (**separation of concerns**)\n",
    "\n",
    "Here is the complete implementation of PreProcessTask:\n",
    "\n",
    "```python\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "class PreProcessTask(Task):\n",
    "    def __init__(self, pre_processing_steps: List[str]):\n",
    "        super().__init__()\n",
    "        self._pre_processing_steps = pre_processing_steps\n",
    "        self.publishes = [\"pre_processed_dataset\"]\n",
    "\n",
    "    def _pre_process(self, text: Dict) -> str:\n",
    "        pre_processed_text = text\n",
    "        for step in self._pre_processing_steps:\n",
    "            if step == \"lower_case\":\n",
    "                pre_processed_text = pre_processed_text.lower()\n",
    "            if step == \"remove_punct\":\n",
    "                pre_processed_text = pre_processed_text.translate(\n",
    "                    str.maketrans('', '', string.punctuation))\n",
    "            if step == \"remove_digits\":\n",
    "                pre_processed_text = re.sub(\n",
    "                    r\"\\d+\", \"<num>\", pre_processed_text)\n",
    "        return pre_processed_text\n",
    "\n",
    "    def run(self, raw_dataset: Dict):\n",
    "        pre_processed_splits = {}\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            pre_processed_sentences = [\n",
    "                self._pre_process(sentence) for sentence in raw_dataset[split][\"sentences\"]]\n",
    "            pre_processed_splits[split] = {\n",
    "                \"sentences\": pre_processed_sentences}\n",
    "        self.save(pre_processed_splits, \"pre_processed_dataset\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Featurization:**\n",
    "\n",
    "Now that we have our datasets prepared and sentences pre-processed, we can now convert these to numerical vectors which can be then fed to classifiers. To this end, we would like to implement two featurizers namely a TFIDF featurizer and a glove featurizer. They can be implemented as two independent tasks which takes preprocessed sentences and publishes vectorized sentences.\n",
    "\n",
    "You may have guessed the pattern already, this task expects pre_processed dataset, which was produced by PreProcessTask. \n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings, DocumentPoolEmbeddings\n",
    "\n",
    "class GloveFeaturizeTask(Task):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.publishes = [\"glove_featurized_dataset\"]\n",
    "\n",
    "    def run(self, pre_processed_dataset: Dict):\n",
    "        featurized_splits = {}\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            sentences = [Sentence(sent)\n",
    "                         for sent in pre_processed_dataset[split][\"sentences\"]]\n",
    "            embedder = DocumentPoolEmbeddings([WordEmbeddings(\"glove\")])\n",
    "            embedder.embed(sentences)\n",
    "            glove_vectors = [sent.embedding.cpu().numpy()\n",
    "                             for sent in sentences]\n",
    "            glove_vectors = np.array(glove_vectors).reshape(\n",
    "                len(glove_vectors), -1)\n",
    "            featurized_splits[split] = {\"vectors\": glove_vectors}\n",
    "        self.save(featurized_splits, \"glove_featurized_dataset\")\n",
    "\n",
    "\n",
    "class TFIDFFeaturizeTask(Task):\n",
    "    def __init__(self, min_df: int, max_features: int):\n",
    "        super().__init__()\n",
    "        self._min_df = min_df\n",
    "        self._max_features = max_features\n",
    "        self.publishes = [\"tfidf_featurized_dataset\"]\n",
    "\n",
    "    def run(self, pre_processed_dataset: Dict):\n",
    "        tfidf_model = TfidfVectorizer(\n",
    "            min_df=self._min_df, max_features=self._max_features)\n",
    "        tfidf_model.fit(pre_processed_dataset[\"train\"][\"sentences\"])\n",
    "        featurized_splits = {}\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            tfidf_vectors = tfidf_model.transform(\n",
    "                pre_processed_dataset[split][\"sentences\"]).toarray()\n",
    "            featurized_splits[split] = {\"vectors\": tfidf_vectors}\n",
    "        self.save(featurized_splits, \"tfidf_featurized_dataset\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Training a classifier**\n",
    "\n",
    "We are all set to train a simple classifier. For this tutorial, let's stick with a simple logistic regression model from Sklearn.\n",
    "For the inputs, we can stack the glove and tfidf vectors (obtained from featurization task results) and for the targets, we can just use the labels from the raw dataset. In the end, this task returns a trained SKlearn classifier.\n",
    "\n",
    "**Note:** You are not limited just to Sklearn. You can train any kind of model using your favorite library (PyTorch, TensorFlow, Keras, PyTorch Lightning, etc) \n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class TrainTask(Task):\n",
    "    def __init__(self, max_iter: int, balanced: str):\n",
    "        super().__init__()\n",
    "        self._max_iter = max_iter\n",
    "        self._class_weight = \"balanced\" if balanced else None\n",
    "        self.publishes = [\"trained_model\"]\n",
    "\n",
    "    def run(self, raw_dataset: Dict, tfidf_featurized_dataset: Dict, glove_featurized_dataset: Dict):\n",
    "        model = LogisticRegression(\n",
    "            max_iter=self._max_iter, class_weight=self._class_weight)\n",
    "        stacked_vectors = np.hstack((tfidf_featurized_dataset[\"train\"][\"vectors\"],\n",
    "                                     glove_featurized_dataset[\"train\"][\"vectors\"]))\n",
    "        model.fit(stacked_vectors, raw_dataset[\"train\"][\"labels\"])\n",
    "        self.save(model, \"trained_model\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Evaluation of classifier**\n",
    "\n",
    "Now, that we have trained a classifier, it is time to evaluate this classifier on all of the dataset splits. This task is straightforward, we will get the featurized dataset splits and the trained model from the results. \n",
    "At the end, EvaluateTask publishes a nested dictionary containing classification reports for each of train, val and test splits.\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class EvaluateTask(Task):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.publishes = [\"evaluation_results\"]\n",
    "\n",
    "    def run(self, raw_dataset: Dict, tfidf_featurized_dataset: Dict, glove_featurized_dataset: Dict,\n",
    "            trained_model: LogisticRegression):\n",
    "        evaluation_results = {}\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            stacked_vectors = np.hstack((tfidf_featurized_dataset[split][\"vectors\"],\n",
    "                                         glove_featurized_dataset[split][\"vectors\"]))\n",
    "            predictions = trained_model.predict(\n",
    "                stacked_vectors)\n",
    "            report = classification_report(\n",
    "                raw_dataset[split][\"labels\"], predictions, output_dict=True)\n",
    "            evaluation_results[split] = {\"classification_report\": report}\n",
    "        self.save(evaluation_results, \"evaluation_results\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create and Run the Pipeline/Task-Graph via FluidML**\n",
    "\n",
    "So far, we have looked into implementing our individual pipeline steps using FluidML's Task class and it was very straightforward.\n",
    "You might be wondering, how to put these tasks together and make them work together as a single pipeline?\n",
    "\n",
    "Thanks to FluidML's TaskSpec API, you can connect these tasks like Lego blocks :)\n",
    "\n",
    "### **1. Instantiate Task Specifications**\n",
    "TaskSpec is a simple wrapper that allows to specify task details task arguments which will be used during instantiation of the task.\n",
    "Let's go ahead and create specs for all our tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all task specs\n",
    "dataset_fetch_task = TaskSpec(task=DatasetFetchTask)\n",
    "pre_process_task = TaskSpec(task=PreProcessTask, task_kwargs={\n",
    "                            \"pre_processing_steps\": [\"lower_case\", \"remove_punct\"]})\n",
    "featurize_task_1 = TaskSpec(\n",
    "    task=GloveFeaturizeTask)\n",
    "featurize_task_2 = TaskSpec(\n",
    "    task=TFIDFFeaturizeTask, task_kwargs={\"min_df\": 5, \"max_features\": 1000})\n",
    "train_task = TaskSpec(task=TrainTask, task_kwargs={\"max_iter\": 50, \"balanced\": True})\n",
    "evaluate_task = TaskSpec(task=EvaluateTask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Registering Task Dependencies**\n",
    "More importantly, TaskSpec also provides `requires()` method to specify predecessor tasks which need to be executed before that particular task.\n",
    "\n",
    "For instance, in our example, we would need DatasetFetchTask to be finished before we start to run PreProcessTask. Similarly,\n",
    "PreProcessTask is required for both FeaturizeTask. \n",
    "\n",
    "Using these task dependencies, FluidML creates a task graph and schedules the tasks considering the dependencies.\n",
    "Not just that, it automatically collects the results from predecessor tasks and makes it available to `run()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies between tasks\n",
    "pre_process_task.requires([dataset_fetch_task])\n",
    "featurize_task_1.requires([pre_process_task])\n",
    "featurize_task_2.requires([pre_process_task])\n",
    "train_task.requires(\n",
    "    [dataset_fetch_task, featurize_task_1, featurize_task_2])\n",
    "evaluate_task.requires(\n",
    "    [dataset_fetch_task, featurize_task_1, featurize_task_2, train_task])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Creating a Final list of Task Specs**\n",
    "We can just hold all these tasks in a list which we will pass it to FluidML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all task specs\n",
    "tasks = [dataset_fetch_task,\n",
    "         pre_process_task,\n",
    "         featurize_task_1, featurize_task_2,\n",
    "         train_task,\n",
    "         evaluate_task]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Run the Pipeline/Task-Graph using Swarm & Flow**\n",
    "Now that we have a final list of task specs which are ready to be run, we just have to create\n",
    "\n",
    "- **Swarm:** which contains several workers which helps to run these tasks parallely. In our example, featurize_task_1 and featurize_task_2 are independent and can be exectued concurrently.\n",
    "- **Flow:** which builds tasks from provided task specifications and creates a task graph which is then processed by Swarm\n",
    "\n",
    "\n",
    "Using swarm and flow, we can just run our tasks using `flow.run(tasks)`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:53] </span><span style=\"color: #000080\">INFO</span>     MainProcess                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/swarm.py\"><span style=\"color: #7f7f7f\">swarm.py</span></a><span style=\"color: #7f7f7f\">:122</span>\n",
       "                             Swarm scheduling task DatasetFetchTask-<span style=\"color: #000080; font-weight: bold\">0</span>.                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1337e0eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:53] </span><span style=\"color: #000080\">INFO</span>     MainProcess                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/swarm.py\"><span style=\"color: #7f7f7f\">swarm.py</span></a><span style=\"color: #7f7f7f\">:122</span>\n",
       "                             Swarm scheduling task DatasetFetchTask-<span style=\"color: #000080; font-weight: bold\">0</span>.                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1337e0e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:55] </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:66</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span> started running task DatasetFetchTask-<span style=\"color: #000080; font-weight: bold\">0</span>.              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:55] </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:66</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span> started running task DatasetFetchTask-<span style=\"color: #000080; font-weight: bold\">0</span>.              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:939</span>\n",
       "                             Starting new HTTPS connection <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>:                              \n",
       "                             s3.amazonaws.com:<span style=\"color: #000080; font-weight: bold\">443</span>                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:939</span>\n",
       "                             Starting new HTTPS connection <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>:                              \n",
       "                             s3.amazonaws.com:<span style=\"color: #000080; font-weight: bold\">443</span>                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1338036d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:56] </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:433</span>\n",
       "                             <span style=\"color: #0000ff; text-decoration: underline\">https://s3.amazonaws.com:443</span> <span style=\"color: #008000\">\"</span><span style=\"color: #808000; font-weight: bold\">HEAD</span><span style=\"color: #008000\"> /datase</span>                      \n",
       "                             <span style=\"color: #008000\">ts.huggingface.co/datasets/datasets/trec/t</span>                      \n",
       "                             <span style=\"color: #008000\">rec.py HTTP/1.1\"</span> <span style=\"color: #000080; font-weight: bold\">200</span> <span style=\"color: #000080; font-weight: bold\">0</span>                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:56] </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:433</span>\n",
       "                             <span style=\"color: #0000ff; text-decoration: underline\">https://s3.amazonaws.com:443</span> <span style=\"color: #008000\">\"</span><span style=\"color: #808000; font-weight: bold\">HEAD</span><span style=\"color: #008000\"> /datase</span>                      \n",
       "                             <span style=\"color: #008000\">ts.huggingface.co/datasets/datasets/trec/t</span>                      \n",
       "                             <span style=\"color: #008000\">rec.py HTTP/1.1\"</span> <span style=\"color: #000080; font-weight: bold\">200</span> <span style=\"color: #000080; font-weight: bold\">0</span>                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:939</span>\n",
       "                             Starting new HTTPS connection <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>:                              \n",
       "                             raw.githubusercontent.com:<span style=\"color: #000080; font-weight: bold\">443</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:939</span>\n",
       "                             Starting new HTTPS connection <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>:                              \n",
       "                             raw.githubusercontent.com:<span style=\"color: #000080; font-weight: bold\">443</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:433</span>\n",
       "                             <span style=\"color: #0000ff; text-decoration: underline\">https://raw.githubusercontent.com:443</span>                           \n",
       "                             <span style=\"color: #008000\">\"</span><span style=\"color: #808000; font-weight: bold\">HEAD</span><span style=\"color: #008000\"> /huggingface/datasets/1.1.3/datasets</span>                      \n",
       "                             <span style=\"color: #008000\">/trec/trec.py HTTP/1.1\"</span> <span style=\"color: #000080; font-weight: bold\">200</span> <span style=\"color: #000080; font-weight: bold\">0</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:433</span>\n",
       "                             <span style=\"color: #0000ff; text-decoration: underline\">https://raw.githubusercontent.com:443</span>                           \n",
       "                             <span style=\"color: #008000\">\"</span><span style=\"color: #808000; font-weight: bold\">HEAD</span><span style=\"color: #008000\"> /huggingface/datasets/1.1.3/datasets</span>                      \n",
       "                             <span style=\"color: #008000\">/trec/trec.py HTTP/1.1\"</span> <span style=\"color: #000080; font-weight: bold\">200</span> <span style=\"color: #000080; font-weight: bold\">0</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:939</span>\n",
       "                             Starting new HTTPS connection <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>:                              \n",
       "                             raw.githubusercontent.com:<span style=\"color: #000080; font-weight: bold\">443</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:939</span>\n",
       "                             Starting new HTTPS connection <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>:                              \n",
       "                             raw.githubusercontent.com:<span style=\"color: #000080; font-weight: bold\">443</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803f40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:433</span>\n",
       "                             <span style=\"color: #0000ff; text-decoration: underline\">https://raw.githubusercontent.com:443</span>                           \n",
       "                             <span style=\"color: #008000\">\"</span><span style=\"color: #808000; font-weight: bold\">HEAD</span><span style=\"color: #008000\"> /huggingface/datasets/1.1.3/datasets</span>                      \n",
       "                             <span style=\"color: #008000\">/trec/dataset_infos.json HTTP/1.1\"</span> <span style=\"color: #000080; font-weight: bold\">200</span> <span style=\"color: #000080; font-weight: bold\">0</span>                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/urllib3/connectionpool.py\"><span style=\"color: #7f7f7f\">connectionpool.py</span></a><span style=\"color: #7f7f7f\">:433</span>\n",
       "                             <span style=\"color: #0000ff; text-decoration: underline\">https://raw.githubusercontent.com:443</span>                           \n",
       "                             <span style=\"color: #008000\">\"</span><span style=\"color: #808000; font-weight: bold\">HEAD</span><span style=\"color: #008000\"> /huggingface/datasets/1.1.3/datasets</span>                      \n",
       "                             <span style=\"color: #008000\">/trec/dataset_infos.json HTTP/1.1\"</span> <span style=\"color: #000080; font-weight: bold\">200</span> <span style=\"color: #000080; font-weight: bold\">0</span>                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:57] </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:71</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span> completed running task                                \n",
       "                             DatasetFetchTask-<span style=\"color: #000080; font-weight: bold\">0</span>.                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:57] </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:71</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span> completed running task                                \n",
       "                             DatasetFetchTask-<span style=\"color: #000080; font-weight: bold\">0</span>.                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803bb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:97</span>\n",
       "                             Finished <span style=\"color: #000080; font-weight: bold\">1</span> from <span style=\"color: #000080; font-weight: bold\">6</span> tasks <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">17</span>%<span style=\"font-weight: bold\">)</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:97</span>\n",
       "                             Finished <span style=\"color: #000080; font-weight: bold\">1</span> from <span style=\"color: #000080; font-weight: bold\">6</span> tasks <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">17</span>%<span style=\"font-weight: bold\">)</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:146</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span> is now scheduling PreProcessTask-<span style=\"color: #000080; font-weight: bold\">1</span>.                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:146</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span> is now scheduling PreProcessTask-<span style=\"color: #000080; font-weight: bold\">1</span>.                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803b20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:140</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span>: Dependencies are not satisfied yet for               \n",
       "                             task TrainTask-<span style=\"color: #000080; font-weight: bold\">4</span>                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:140</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span>: Dependencies are not satisfied yet for               \n",
       "                             task TrainTask-<span style=\"color: #000080; font-weight: bold\">4</span>                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803f40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:140</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span>: Dependencies are not satisfied yet for               \n",
       "                             task EvaluateTask-<span style=\"color: #000080; font-weight: bold\">5</span>                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1338035e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:140</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span>: Dependencies are not satisfied yet for               \n",
       "                             task EvaluateTask-<span style=\"color: #000080; font-weight: bold\">5</span>                                             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:66</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> started running task PreProcessTask-<span style=\"color: #000080; font-weight: bold\">1</span>.                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1338035e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:66</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> started running task PreProcessTask-<span style=\"color: #000080; font-weight: bold\">1</span>.                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:71</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> completed running task PreProcessTask-<span style=\"color: #000080; font-weight: bold\">1</span>.              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1338035e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:71</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> completed running task PreProcessTask-<span style=\"color: #000080; font-weight: bold\">1</span>.              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:97</span>\n",
       "                             Finished <span style=\"color: #000080; font-weight: bold\">2</span> from <span style=\"color: #000080; font-weight: bold\">6</span> tasks <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">33</span>%<span style=\"font-weight: bold\">)</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:97</span>\n",
       "                             Finished <span style=\"color: #000080; font-weight: bold\">2</span> from <span style=\"color: #000080; font-weight: bold\">6</span> tasks <span style=\"font-weight: bold\">(</span><span style=\"color: #000080; font-weight: bold\">33</span>%<span style=\"font-weight: bold\">)</span>                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:146</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> is now scheduling TFIDFFeaturizeTask-<span style=\"color: #000080; font-weight: bold\">2</span>.               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:146</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> is now scheduling TFIDFFeaturizeTask-<span style=\"color: #000080; font-weight: bold\">2</span>.               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:146</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> is now scheduling GloveFeaturizeTask-<span style=\"color: #000080; font-weight: bold\">3</span>.               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                         <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:146</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> is now scheduling GloveFeaturizeTask-<span style=\"color: #000080; font-weight: bold\">3</span>.               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:66</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> started running task                                  \n",
       "                             GloveFeaturizeTask-<span style=\"color: #000080; font-weight: bold\">3</span>.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:66</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">0</span> started running task                                  \n",
       "                             GloveFeaturizeTask-<span style=\"color: #000080; font-weight: bold\">3</span>.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:66</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span> started running task                                  \n",
       "                             TFIDFFeaturizeTask-<span style=\"color: #000080; font-weight: bold\">2</span>.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803ac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">3</span>                                          <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/dolphin.py\"><span style=\"color: #7f7f7f\">dolphin.py</span></a><span style=\"color: #7f7f7f\">:66</span>\n",
       "                             Dolphin <span style=\"color: #000080; font-weight: bold\">1</span> started running task                                  \n",
       "                             TFIDFFeaturizeTask-<span style=\"color: #000080; font-weight: bold\">2</span>.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:58] </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                           <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/gensim/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:431</span>\n",
       "                             loading Word2VecKeyedVectors object from <span style=\"color: #800080\">/Users/lar</span>             \n",
       "                             <span style=\"color: #800080\">shillebrand/.flair/embeddings/</span><span style=\"color: #ff00ff\">glove.gensim</span>                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803ac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[02/11/21 00:48:58] </span><span style=\"color: #000080\">INFO</span>     Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                           <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/gensim/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:431</span>\n",
       "                             loading Word2VecKeyedVectors object from <span style=\"color: #800080\">/Users/lar</span>             \n",
       "                             <span style=\"color: #800080\">shillebrand/.flair/embeddings/</span><span style=\"color: #ff00ff\">glove.gensim</span>                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/smart_open/smart_open_lib.py\"><span style=\"color: #7f7f7f\">smart_open_lib.py</span></a><span style=\"color: #7f7f7f\">:172</span>\n",
       "                             <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'uri'</span>: <span style=\"color: #008000\">'/Users/larshillebrand/.flair/embe</span>                      \n",
       "                             <span style=\"color: #008000\">ddings/glove.gensim'</span>, <span style=\"color: #008000\">'mode'</span>: <span style=\"color: #008000\">'rb'</span>,                             \n",
       "                             <span style=\"color: #008000\">'buffering'</span>: <span style=\"color: #000080; font-weight: bold\">-1</span>, <span style=\"color: #008000\">'encoding'</span>: <span style=\"color: #800080; font-style: italic\">None</span>,                              \n",
       "                             <span style=\"color: #008000\">'errors'</span>: <span style=\"color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000\">'newline'</span>: <span style=\"color: #800080; font-style: italic\">None</span>,                                \n",
       "                             <span style=\"color: #008000\">'closefd'</span>: <span style=\"color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000\">'opener'</span>: <span style=\"color: #800080; font-style: italic\">None</span>,                                \n",
       "                             <span style=\"color: #008000\">'ignore_ext'</span>: <span style=\"color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000\">'transport_params'</span>:                        \n",
       "                             <span style=\"color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803ac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">                    </span><span style=\"color: #008000\">DEBUG</span>    Dolphin-<span style=\"color: #000080; font-weight: bold\">2</span>                                  <a href=\"file:///Users/larshillebrand/anaconda3/envs/fluidml/lib/python3.8/site-packages/smart_open/smart_open_lib.py\"><span style=\"color: #7f7f7f\">smart_open_lib.py</span></a><span style=\"color: #7f7f7f\">:172</span>\n",
       "                             <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'uri'</span>: <span style=\"color: #008000\">'/Users/larshillebrand/.flair/embe</span>                      \n",
       "                             <span style=\"color: #008000\">ddings/glove.gensim'</span>, <span style=\"color: #008000\">'mode'</span>: <span style=\"color: #008000\">'rb'</span>,                             \n",
       "                             <span style=\"color: #008000\">'buffering'</span>: <span style=\"color: #000080; font-weight: bold\">-1</span>, <span style=\"color: #008000\">'encoding'</span>: <span style=\"color: #800080; font-style: italic\">None</span>,                              \n",
       "                             <span style=\"color: #008000\">'errors'</span>: <span style=\"color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000\">'newline'</span>: <span style=\"color: #800080; font-style: italic\">None</span>,                                \n",
       "                             <span style=\"color: #008000\">'closefd'</span>: <span style=\"color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000\">'opener'</span>: <span style=\"color: #800080; font-style: italic\">None</span>,                                \n",
       "                             <span style=\"color: #008000\">'ignore_ext'</span>: <span style=\"color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000\">'transport_params'</span>:                        \n",
       "                             <span style=\"color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x133803c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot close a process while it is still running. You should first call join() or terminate().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eaf7f3127f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/phd/fluidml/fluidml/flow/flow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, task_specs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_tasks_to_force_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/phd/fluidml/fluidml/swarm/swarm.py\u001b[0m in \u001b[0;36mwork\u001b[0;34m(self, tasks)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdolphin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdolphins\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mdolphin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fluidml/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fluidml/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fluidml/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eaf7f3127f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m            return_results=True) as swarm:\n\u001b[1;32m      3\u001b[0m     \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/phd/fluidml/fluidml/swarm/swarm.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     78\u001b[0m                  \u001b[0mexc_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseException\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                  exc_tb: Optional[TracebackType]):\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/phd/fluidml/fluidml/swarm/swarm.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdolphin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdolphins\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mdolphin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_listener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fluidml/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 raise ValueError(\"Cannot close a process while it is still running. \"\n\u001b[0m\u001b[1;32m    182\u001b[0m                                  \"You should first call join() or terminate().\")\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot close a process while it is still running. You should first call join() or terminate()."
     ]
    }
   ],
   "source": [
    "with Swarm(n_dolphins=2,\n",
    "           return_results=True) as swarm:\n",
    "    flow = Flow(swarm=swarm)\n",
    "    results = flow.run(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Results**\n",
    "We can now go over the results and fetch a task's result using its name, which would give task results and task_config (up until that task in the graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "    <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">50</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000\">'EvaluateTask'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff5dc858e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results[\"EvaluateTask\"][\"config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000\">'classification_report'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.8582089552238806</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.8333333333333334</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.8455882352941176</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">138</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.7945205479452054</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.6170212765957447</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.6946107784431137</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">94</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'2'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.35</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.7777777777777778</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.48275862068965514</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">9</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'3'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.8955223880597015</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.9230769230769231</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9090909090909091</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">65</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'4'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.9345794392523364</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.8849557522123894</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9090909090909091</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">113</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'5'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.7878787878787878</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.9629629629629629</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.8666666666666665</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">81</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'accuracy'</span>: <span style=\"color: #000080; font-weight: bold\">0.836</span>,\n",
       "        <span style=\"color: #008000\">'macro avg'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.7701183530599853</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.833188004326522</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.7846343532125619</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">500</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'weighted avg'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.8478047620106426</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.836</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.8366951980972592</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">500</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff50207f810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results[\"EvaluateTask\"][\"result\"][\"evaluation_results\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Grid Search:**\n",
    "\n",
    "We can extend this pipeline and include grid search to find hyper-parameter tuning on the whole pipeline.\n",
    "To enable grid search on a particular task, we just have to wrap it with `GridTaskSpec` instead of `TaskSpec`.\n",
    "\n",
    "For example, for the training task, we can wrap it with `train_task = GridTaskSpec(task=TrainTask, gs_config={\"max_iter\": [50, 100], \"balanced\": [True, False]})`.\n",
    "\n",
    "Internally, Flow would expand this task into 4 tasks with provided combinations of `max_iter` and `balanced`. \n",
    "Not only that, any successor tasks (for instance, evaluate task) in the task graph will also be automatically extended. In our example, we would have four evaluate tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Selection Task:**\n",
    "\n",
    "Ok that's nice. We have now several evaluation tasks and once we run this task graph through Flow, we will have several evaluation tasks and their results.\n",
    "We can implement a model selection task, which consolidates these results and fetches the best config for the pipeline.\n",
    "\n",
    "```python\n",
    "class ModelSelectionTask(Task):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.publishes = [\"best_config\", \"best_performance\"]\n",
    "\n",
    "    def run(self, reduced_results: List[Dict]):\n",
    "        sorted_results = sorted(reduced_results, key=lambda model_result: model_result[\"result\"]\n",
    "                                [\"evaluation_results\"][\"val\"][\"classification_report\"][\"macro avg\"][\"f1-score\"],\n",
    "                                reverse=True)\n",
    "        self.save(sorted_results[0][\"config\"], \"best_config\")\n",
    "        self.save(sorted_results[1][\"result\"], \"best_performance\")\n",
    "```\n",
    "\n",
    "\n",
    "**Note:** Now, we can attach the EvaluationTask as a predecessor to ModelSelectionTask. However, if we do it naively, we would end up with 4 model selection tasks since we have 4 evaluation tasks.\n",
    "So, we just have to specify `reduce=True` so only one instance of model selection task is created and all of the evaluation tasks are attached as parents to it.\n",
    "\n",
    "```python\n",
    "model_selection_task = TaskSpec(task=ModelSelectionTask, reduce=True)\n",
    "model_selection_task.requires([evaluate_task])\n",
    "```\n",
    "Finally, putting all of these together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all task specs\n",
    "dataset_fetch_task = TaskSpec(task=DatasetFetchTask)\n",
    "pre_process_task = TaskSpec(task=PreProcessTask, task_kwargs={\n",
    "                            \"pre_processing_steps\": [\"lower_case\", \"remove_punct\"]})\n",
    "featurize_task_1 = TaskSpec(\n",
    "    task=GloveFeaturizeTask)\n",
    "featurize_task_2 = GridTaskSpec(\n",
    "    task=TFIDFFeaturizeTask, gs_config={\"min_df\": 5, \"max_features\": [1000, 2000]})\n",
    "train_task = GridTaskSpec(task=TrainTask, gs_config={\n",
    "                          \"max_iter\": [50, 100], \"balanced\": [True, False]})\n",
    "evaluate_task = TaskSpec(task=EvaluateTask)\n",
    "model_selection_task = TaskSpec(\n",
    "    task=ModelSelectionTask, reduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies between tasks\n",
    "pre_process_task.requires([dataset_fetch_task])\n",
    "featurize_task_1.requires([pre_process_task])\n",
    "featurize_task_2.requires([pre_process_task])\n",
    "train_task.requires(\n",
    "    [dataset_fetch_task, featurize_task_1, featurize_task_2])\n",
    "evaluate_task.requires(\n",
    "    [dataset_fetch_task, featurize_task_1, featurize_task_2, train_task])\n",
    "model_selection_task.requires([evaluate_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all tasks\n",
    "tasks = [dataset_fetch_task,\n",
    "         pre_process_task,\n",
    "         featurize_task_1, featurize_task_2,\n",
    "         train_task,\n",
    "         evaluate_task,\n",
    "         model_selection_task]\n",
    "\n",
    "with Swarm(n_dolphins=2,\n",
    "           return_results=True) as swarm:\n",
    "    flow = Flow(swarm=swarm)\n",
    "    results = flow.run(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Choosing the best Config and best performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "    <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">100</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000\">'EvaluateTask'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff5dc787310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000\">'classification_report'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.8543046357615894</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.9347826086956522</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.8927335640138409</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">138</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.8192771084337349</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.723404255319149</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.768361581920904</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">94</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'2'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">1.0</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.7777777777777778</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.8750000000000001</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">9</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'3'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.9104477611940298</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.9384615384615385</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9242424242424243</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">65</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'4'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.9696969696969697</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.8495575221238938</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.9056603773584906</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">113</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'5'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.8172043010752689</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.9382716049382716</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.8735632183908048</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">81</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'accuracy'</span>: <span style=\"color: #000080; font-weight: bold\">0.874</span>,\n",
       "        <span style=\"color: #008000\">'macro avg'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.8951551293602655</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.8603758845527136</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.8732601943210775</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">500</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'weighted avg'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'precision'</span>: <span style=\"color: #000080; font-weight: bold\">0.8777089967366734</span>,\n",
       "            <span style=\"color: #008000\">'recall'</span>: <span style=\"color: #000080; font-weight: bold\">0.874</span>,\n",
       "            <span style=\"color: #008000\">'f1-score'</span>: <span style=\"color: #000080; font-weight: bold\">0.8729444428827944</span>,\n",
       "            <span style=\"color: #008000\">'support'</span>: <span style=\"color: #000080; font-weight: bold\">500</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff5020bb510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results[\"ModelSelectionTask\"][\"result\"][\"best_config\"])\n",
    "print(results[\"ModelSelectionTask\"][\"result\"][\"best_performance\"][\"evaluation_results\"][\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this best config, one can get the corresponding model from TrainTask results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'result'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'trained_model'</span>: LogisticRegression<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">class_weight</span>=<span style=\"color: #008000\">'balanced'</span>, <span style=\"color: #808000\">max_iter</span>=<span style=\"color: #000080; font-weight: bold\">50</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">50</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'result'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'trained_model'</span>: LogisticRegression<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">max_iter</span>=<span style=\"color: #000080; font-weight: bold\">50</span><span style=\"font-weight: bold\">)}</span>,\n",
       "        <span style=\"color: #008000\">'config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">50</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'result'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'trained_model'</span>: LogisticRegression<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">class_weight</span>=<span style=\"color: #008000\">'balanced'</span><span style=\"font-weight: bold\">)}</span>,\n",
       "        <span style=\"color: #008000\">'config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">100</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'result'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'trained_model'</span>: LogisticRegression<span style=\"font-weight: bold\">()}</span>,\n",
       "        <span style=\"color: #008000\">'config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">100</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'result'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'trained_model'</span>: LogisticRegression<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">class_weight</span>=<span style=\"color: #008000\">'balanced'</span>, <span style=\"color: #808000\">max_iter</span>=<span style=\"color: #000080; font-weight: bold\">50</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000\">'config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">2000</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">50</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'result'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'trained_model'</span>: LogisticRegression<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">max_iter</span>=<span style=\"color: #000080; font-weight: bold\">50</span><span style=\"font-weight: bold\">)}</span>,\n",
       "        <span style=\"color: #008000\">'config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">2000</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">50</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'result'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'trained_model'</span>: LogisticRegression<span style=\"font-weight: bold\">(</span><span style=\"color: #808000\">class_weight</span>=<span style=\"color: #008000\">'balanced'</span><span style=\"font-weight: bold\">)}</span>,\n",
       "        <span style=\"color: #008000\">'config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">2000</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">100</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000\">'result'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'trained_model'</span>: LogisticRegression<span style=\"font-weight: bold\">()}</span>,\n",
       "        <span style=\"color: #008000\">'config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000\">'DatasetFetchTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'PreProcessTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'pre_processing_steps'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000\">'lower_case'</span>, <span style=\"color: #008000\">'remove_punct'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000\">'GloveFeaturizeTask'</span>: <span style=\"font-weight: bold\">{}</span>,\n",
       "            <span style=\"color: #008000\">'TFIDFFeaturizeTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'min_df'</span>: <span style=\"color: #000080; font-weight: bold\">5</span>, <span style=\"color: #008000\">'max_features'</span>: <span style=\"color: #000080; font-weight: bold\">2000</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000\">'TrainTask'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000\">'max_iter'</span>: <span style=\"color: #000080; font-weight: bold\">100</span>, <span style=\"color: #008000\">'balanced'</span>: <span style=\"color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7ff5020bb510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results[\"TrainTask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/fluidml/fluidml/main/logo/fluid_ml_logo.png\" width=\"400px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
