{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "import yaml\n",
    "\n",
    "# from task_functions import parse, preprocess, featurize_tokens, featurize_cells, train, evaluate\n",
    "from fluidml.common import Resource\n",
    "from fluidml.flow import Flow\n",
    "from fluidml.flow import GridTaskSpec, TaskSpec\n",
    "from fluidml.swarm import Swarm\n",
    "from fluidml.storage import LocalFileStore, MongoDBStore, InMemoryStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(results: Dict, in_dir: str):\n",
    "    return {}\n",
    "\n",
    "\n",
    "def preprocess(results: Dict, pipeline: List[str], abc: List[int]):\n",
    "    return {}\n",
    "\n",
    "def featurize_tokens(results: Dict, type_: str, batch_size: int):\n",
    "    return {}\n",
    "\n",
    "\n",
    "def featurize_cells(results: Dict, type_: str, batch_size: int):\n",
    "    return {}\n",
    "\n",
    "\n",
    "def train(results: Dict, model, dataloader, evaluator, optimizer, num_epochs):\n",
    "    return {'score': 2.}  # 'score': 2.\n",
    "\n",
    "\n",
    "def evaluate(results: Dict, metric: str):\n",
    "    print(results)\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.getcwd()\n",
    "base_dir = os.path.join(CURRENT_DIR, 'experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_task = GridTaskSpec(task=parse, gs_config={\"in_dir\": \"/some/dir\"})\n",
    "preprocess_task = GridTaskSpec(task=preprocess, gs_config={\"pipeline\": ['a', 'b'], \"abc\": [1,2]})\n",
    "featurize_tokens_task = GridTaskSpec(task=featurize_tokens, gs_config={\"type_\": \"flair\", 'batch_size': 2})\n",
    "featurize_cells_task = GridTaskSpec(task=featurize_cells, gs_config={\"type_\": \"glove\", \"batch_size\": 4})\n",
    "train_task = GridTaskSpec(task=train, gs_config={\"model\": \"mlp\", \"dataloader\": \"x\", \"evaluator\": \"y\", \"optimizer\": \"adam\", \"num_epochs\": 10})\n",
    "evaluate_task = TaskSpec(task=evaluate, reduce=True, task_kwargs={\"metric\": \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies between tasks\n",
    "preprocess_task.requires([parse_task])\n",
    "featurize_tokens_task.requires([preprocess_task])\n",
    "featurize_cells_task.requires([preprocess_task])\n",
    "train_task.requires([featurize_tokens_task, featurize_cells_task])\n",
    "evaluate_task.requires([train_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all tasks\n",
    "tasks = [parse_task,\n",
    "         preprocess_task,\n",
    "         featurize_tokens_task,\n",
    "         featurize_cells_task,\n",
    "         train_task,\n",
    "         evaluate_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_store = LocalFileStore(base_dir=base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[19:38:06] </span>Swarm scheduling task parse-<span style=\"color: #000080; font-weight: bold\">0</span>.                                        <a href=\"file:///Users/larshillebrand/Documents/phd/fluidml/fluidml/swarm/swarm.py\"><span style=\"color: #7f7f7f\">swarm.py</span></a><span style=\"color: #7f7f7f\">:101</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x11c6a1ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run tasks in parallel (GridTaskSpecs are expanded based on grid search arguments)\n",
    "with Swarm(n_dolphins=4, results_store=results_store) as swarm:\n",
    "    flow = Flow(swarm=swarm, force='all')\n",
    "    results = flow.run(tasks)\n",
    "    # print(results)\n",
    "    # print('bla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
