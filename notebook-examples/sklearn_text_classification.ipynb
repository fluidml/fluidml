{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using Sklearn and FluidML\n",
    "In this notebook, let's implement a complete pipeline to classify sentences using Sklearn and FluidML. This pipeline consists of several steps/tasks:\n",
    "- Dataset collection\n",
    "- Dataset pre-processing\n",
    "- Featurization\n",
    "- Training a classifier\n",
    "- Evaluation of classifier\n",
    "\n",
    "All of these steps can be naturally implemented using FluidML's task API which can be put-together to form a complete flow.\n",
    "\n",
    "Additionally, we can also perform hyper-parameter tuning and select the best model using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from fluidml.common import Task, Resource\n",
    "from typing import Dict, Any, Tuple, List\n",
    "\n",
    "class DatasetFetchTask(Task):\n",
    "    def __init__(self, name: str, id_: int):\n",
    "        super().__init__(name, id_)\n",
    "\n",
    "    def _get_split(self, dataset, split):\n",
    "        if split == \"test\":\n",
    "            return dataset[split]\n",
    "        elif split in [\"train\", \"val\"]:\n",
    "            splitted = list(dataset[\"train\"])\n",
    "            split_index = int(0.7 * len(splitted))\n",
    "            return splitted[:split_index] if split == \"train\" else splitted[split_index:]\n",
    "\n",
    "    def _get_sentences_and_labels(self, dataset) -> Tuple[List[str], List[str]]:\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        for item in dataset:\n",
    "            sentences.append(item[\"text\"])\n",
    "            labels.append(item[\"label-coarse\"])\n",
    "        return sentences, labels\n",
    "\n",
    "    def run(self, results: Dict[str, Any], resource: Resource):\n",
    "        dataset = load_dataset(\"trec\")\n",
    "        splits = [\"train\", \"val\", \"test\"]\n",
    "        task_results = {}\n",
    "        for split in splits:\n",
    "            dataset_split = self._get_split(dataset, split)\n",
    "            sentences, labels = self._get_sentences_and_labels(dataset_split)\n",
    "            split_results = {\n",
    "                \"sentences\": sentences,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "            task_results[split] = split_results\n",
    "        print(task_results)\n",
    "        return task_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Pre-processing:\n",
    "Now that we have our raw datasets prepared, next, we can apply some pre-processing to clean them up a bit, such as removing punctuations, removing digits and making lower case etc. We will implement this logic into a PreProcessTask. \n",
    "\n",
    "Note, this task assumes that the raw sentences are available to it via results dictionary. This is ensured by FluidML itself. Therefore, PreProcessTask just have to implement its own logic and return pre-processed sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "class PreProcessTask(Task):\n",
    "    def __init__(self, name: str, id_: int, pre_processing_steps: List[str]):\n",
    "        super().__init__(name, id_)\n",
    "        self._pre_processing_steps = pre_processing_steps\n",
    "\n",
    "    def _pre_process(self, text: str) -> str:\n",
    "        pre_processed_text = text\n",
    "        for step in self._pre_processing_steps:\n",
    "            if step == \"lower_case\":\n",
    "                pre_processed_text = pre_processed_text.lower()\n",
    "            if step == \"remove_punct\":\n",
    "                pre_processed_text = pre_processed_text.translate(\n",
    "                    str.maketrans('', '', string.punctuation))\n",
    "            if step == \"remove_digits\":\n",
    "                pre_processed_text = re.sub(\n",
    "                    r\"\\d+\", \"<num>\", pre_processed_text)\n",
    "        return pre_processed_text\n",
    "\n",
    "    def run(self, results: Dict[str, Any], resource: Resource):\n",
    "        task_results = {}\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            pre_processed_sentences = [\n",
    "                self._pre_process(sentence) for sentence in results[\"dataset\"][\"result\"][split][\"sentences\"]]\n",
    "            task_results[split] = {\"sentences\": pre_processed_sentences}\n",
    "        return task_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Featurization:\n",
    "\n",
    "Now that we have cleaned sentences, we can now convert these to numerical vectors which can be then fed to classifiers. To this end, we would like to implement two featurizers namely a TFIDF featurizer and a glove featurizer. They can be implemented as two independent tasks which takes preprocessed sentences and returns vectorized sentences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/raj/miniconda2/envs/fluidml/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings, DocumentPoolEmbeddings\n",
    "\n",
    "class TFIDFFeaturizeTask(Task):\n",
    "    def __init__(self, name: str, id_: int, min_df: int, max_features: int):\n",
    "        super().__init__(name, id_)\n",
    "        self._min_df = min_df\n",
    "        self._max_features = max_features\n",
    "\n",
    "    def run(self, results: Dict[str, Any], resource: Resource):\n",
    "        tfidf_model = TfidfVectorizer(\n",
    "            min_df=self._min_df, max_features=self._max_features)\n",
    "        tfidf_model.fit(results[\"pre_process\"][\"result\"][\"train\"][\"sentences\"])\n",
    "        task_results = {}\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            tfidf_vectors = tfidf_model.transform(\n",
    "                results[\"pre_process\"][\"result\"][split][\"sentences\"]).toarray()\n",
    "            task_results[split] = {\"vectors\": tfidf_vectors}\n",
    "        return task_results\n",
    "\n",
    "\n",
    "class GloveFeaturizeTask(Task):\n",
    "    def __init__(self, name: str, id_: int):\n",
    "        super().__init__(name, id_)\n",
    "\n",
    "    def run(self, results: Dict[str, Any], resource: Resource):\n",
    "        task_results = {}\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            sentences = [Sentence(sent)\n",
    "                         for sent in results[\"pre_process\"][\"result\"][split][\"sentences\"]]\n",
    "            embedder = DocumentPoolEmbeddings([WordEmbeddings(\"glove\")])\n",
    "            embedder.embed(sentences)\n",
    "            glove_vectors = [sent.embedding.cpu().numpy()\n",
    "                             for sent in sentences]\n",
    "            glove_vectors = np.array(glove_vectors).reshape(\n",
    "                len(glove_vectors), -1)\n",
    "            task_results[split] = {\"vectors\": glove_vectors}\n",
    "        return task_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class TrainTask(Task):\n",
    "    def __init__(self, name: str, id_: int, max_iter: int, class_weight: str):\n",
    "        super().__init__(name, id_)\n",
    "        self._max_iter = max_iter\n",
    "        self._class_weight = class_weight\n",
    "\n",
    "    def run(self, results: Dict[str, Any], resource: Resource):\n",
    "        model = LogisticRegression(\n",
    "            max_iter=self._max_iter, class_weight=self._class_weight)\n",
    "        stacked_vectors = np.hstack((results[\"tfidf_featurize\"][\"result\"][\"train\"][\"vectors\"],\n",
    "                                     results[\"glove_featurize\"][\"result\"][\"train\"][\"vectors\"]))\n",
    "        model.fit(stacked_vectors,\n",
    "                  results[\"dataset\"][\"result\"][\"train\"][\"labels\"])\n",
    "        task_results = {\n",
    "            \"model\": model\n",
    "        }\n",
    "        return task_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class EvaluateTask(Task):\n",
    "    def __init__(self, name: str, id_: int):\n",
    "        super().__init__(name, id_)\n",
    "\n",
    "    def run(self, results: Dict[str, Any], resource: Resource):\n",
    "        task_results = {}\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            stacked_vectors = np.hstack((results[\"tfidf_featurize\"][\"result\"][split][\"vectors\"],\n",
    "                                         results[\"glove_featurize\"][\"result\"][split][\"vectors\"]))\n",
    "            predictions = results[\"train\"][\"result\"][\"model\"].predict(\n",
    "                stacked_vectors)\n",
    "            report = classification_report(\n",
    "                results[\"dataset\"][\"result\"][split][\"labels\"], predictions, output_dict=True)\n",
    "            task_results[split] = {\"classification_report\": report}\n",
    "        return task_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all of them together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fluidml.swarm import Swarm\n",
    "from fluidml.flow import Flow, TaskSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all task specs\n",
    "dataset_fetch_task = TaskSpec(task=DatasetFetchTask, name=\"dataset\")\n",
    "pre_process_task = TaskSpec(task=PreProcessTask, name=\"pre_process\", task_kwargs={\n",
    "                            \"pre_processing_steps\": [\"lower_case\", \"remove_punct\"]})\n",
    "featurize_task_1 = TaskSpec(\n",
    "    task=GloveFeaturizeTask, name=\"glove_featurize\")\n",
    "featurize_task_2 = TaskSpec(\n",
    "    task=TFIDFFeaturizeTask, name=\"tfidf_featurize\", task_kwargs={\"min_df\": 5, \"max_features\": 1000})\n",
    "train_task = TaskSpec(task=TrainTask, name=\"train\",\n",
    "                        task_kwargs={\"max_iter\": 50, \"class_weight\": \"balanced\"})\n",
    "evaluate_task = TaskSpec(task=EvaluateTask, name=\"evaluate\")\n",
    "\n",
    "# dependencies between tasks\n",
    "pre_process_task.requires([dataset_fetch_task])\n",
    "featurize_task_1.requires([pre_process_task])\n",
    "featurize_task_2.requires([pre_process_task])\n",
    "train_task.requires(\n",
    "    [dataset_fetch_task, featurize_task_1, featurize_task_2])\n",
    "evaluate_task.requires(\n",
    "    [dataset_fetch_task, featurize_task_1, featurize_task_2, train_task])\n",
    "\n",
    "# all tasks\n",
    "tasks = [dataset_fetch_task,\n",
    "            pre_process_task,\n",
    "            featurize_task_1, featurize_task_2,\n",
    "            train_task,\n",
    "            evaluate_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[13:52:02] </span>Swarm scheduling task dataset-<span style=\"color: #000080; font-weight: bold\">0</span>.                                      <a href=\"file:///home/raj/projects/fluidml/fluidml/swarm/swarm.py\"><span style=\"color: #7f7f7f\">swarm.py</span></a><span style=\"color: #7f7f7f\">:105</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7f5d70922b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed everything and now collecting results\n",
      "Results dictionary: {}\n",
      "Task datasetdoes not return something None\n"
     ]
    },
    {
     "ename": "TaskResultTypeError",
     "evalue": "Each task has to return a dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTaskResultTypeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ff8809b6c464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             return_results=True) as swarm:\n\u001b[1;32m      4\u001b[0m     \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswarm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"evaluate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fluidml/fluidml/flow/flow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, task_specs)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mordered_task_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_tasks_to_force_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fluidml/fluidml/swarm/swarm.py\u001b[0m in \u001b[0;36mwork\u001b[0;34m(self, tasks)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# return results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fluidml/fluidml/swarm/swarm.py\u001b[0m in \u001b[0;36m_collect_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m         results = pack_results(results_store=self.results_store,\n\u001b[1;32m     90\u001b[0m                                \u001b[0mtask_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_configs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                                return_results=self.return_results)\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fluidml/fluidml/storage/utils.py\u001b[0m in \u001b[0;36mpack_results\u001b[0;34m(results_store, task_configs, return_results)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Task {task_name}does not return something {result}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTaskResultTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Each task has to return a dict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTaskResultTypeError\u001b[0m: Each task has to return a dict"
     ]
    }
   ],
   "source": [
    "with Swarm(n_dolphins=2,\n",
    "            refresh_every=10,\n",
    "            return_results=True) as swarm:\n",
    "    flow = Flow(swarm=swarm)\n",
    "    results = flow.run(tasks)\n",
    "print(results[\"evaluate\"][\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
